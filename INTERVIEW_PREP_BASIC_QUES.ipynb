{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcCAYQWJRFUcD7UEGkbx/m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKASHPATI007/Interview-Prep-Basic-ML-Notes-Ques-/blob/main/INTERVIEW_PREP_BASIC_QUES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Tell me a little about yourself.**"
      ],
      "metadata": {
        "id": "knyIckMHiZgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hi,  my name is Akashpati Mishra. I had done B.tech in Mechanical engineering. After graduating I joined my family business. We have a building material and sanitaryware shops. There i got a chance to learn about inventory management, customer handling. As I saw that growth in our business is saturate after a few time and I can utilise me to other field. from childhood I was intrested in stats and graph and I also want work in field which is growing with time so I was searching for field where i can utilize my intrest so came to know about data science. first I started learning by myself learnt python then after 2 moths learning by my own I soon realized that to grasp fast a proper guidance is required so I joined Almabetter as a trainee and from past 1 year I had learnt a lot of skills and also i had done few real time projects to get practical experience. Firstly I learnt Python and its few libraries then I learnt SQl then I had done a small project on Python. After that I learnt some of visualisation tools like Seaborn, Tableau, PowerBi, after I learnt Machine learning and also I had done 3 projects on Machine Learning"
      ],
      "metadata": {
        "id": "35-JBpXQik2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Tell me about your project. What project you had done.**"
      ],
      "metadata": {
        "id": "eV2RCUDMpSc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly I had done an **EDA** project on **Telecom customer churn analysis** where I analyze the data and discovers factors responsible for customer churn. The next project I had done is **Rental bike demand prediction** where I had done prediction of bike count required at  each hour for stable supply of rental bike. Third one is **Credit card default prediction** where our main aim is to develop a mechanism to predict the credit card default beforehand and to identify the potential customer base that can be offered various credit instruments so as to invite minimum default. And my last project is **Online retail customer segmentaion** where I divide the customer based on their behaviour"
      ],
      "metadata": {
        "id": "yrGrjbUapqXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. which is your favorite project and why?**"
      ],
      "metadata": {
        "id": "CTbKHXLQiCyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every project takes it's own time and gives different insights so for me every project is special and I always though that the project which gives less error will liked by every data scientist. But if you asked on persional level in project which I had done I like regression project which is rental bike sharing demand prediction because I had given a lot of time on this project and also I always use rental bike may be you have heard a name \"rapido bike\" so I more realize and thought at tym of doing project that \"oh this way they supplying and fullfilling demands\" and also came to know about what challenges that they face."
      ],
      "metadata": {
        "id": "5InsM6iZiF4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Tell me more about your project what you had done on the project which algorithm you used and why did you pick that and what insights you had drawn from your project?**"
      ],
      "metadata": {
        "id": "B5INBYLpktPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Rental bike demand prediction-**\n",
        "\n",
        "In this project  I firstly remove null and duplicate values and take that variable which will necessary for for business problem then I analyse data with various variable using univariate, bivariate and multi variate analysis.In univariate basically I copare the data with dist and box plot and see if there any outliar is present or not and draw different conclusion from it. In bivariate i used graphs line bar plot and line chart to see how categorical variable were changes. Then I used heat map to see the variable which is highly correlated and also used OLS model too see the variable which is variable suffer from **multi colliniarity**. Then I  do some feature engineering on the data like **level encoding** , creating some **dummy variable**\n",
        "\n",
        "After doing this cleaning process I started training my model by spliting the data into train-test split then I used **Linear Regression ** model , Lasso Regression, Ridge regression, Elastic net regression then used decision tree like random forest, gradient boosting, I also used grid search random forest and gradient boosting.\n",
        "\n",
        "And then evaluate my model by using different matrices like **MSE, MAE, RMSE,R2 score** and found that Random forest And gradient boost grid search CV having highest r2 score and best fit the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "6QG_vndFrPZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What is machine learning and what are its types and explain its types?**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SjOW5yBklsxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning-** Machine learning is a branch of AI and computer science which automatically improves their performance through past experience\n",
        "\n",
        "**Types-**\n",
        "\n",
        "**1. Supervised Learning-**It is defined by its use of **labeled datasets** to train algorithms that to classify data or predict outcomes accurately.\n",
        "\n",
        "**Example-** spam filters, fraud detection systems\n",
        "\n",
        "**Labeled data-**Labeled data is a designation for pieces of data that have been tagged with one or more labels identifying certain properties or characteristics, or classifications or contained objects.\n",
        "\n",
        "**Unlabelled data-**Unlabeled data consists of data which is either taken from nature or created by human to explore the scientific patterns behind it. Some examples of unlabeled data might include photos, audio recordings, videos, news articles, tweets, x-rays, etc.\n",
        "\n",
        "**2. Unsupervised Learning-**Unsupervised learning is a type of machine learning in which models are trained using **unlabeled dataset** and are allowed to act on that data without any supervision.\n",
        "\n",
        "**Example-**\n",
        "\n",
        "An example of unsupervised machine learning would be a case where a supermarket wants to increase its revenue. It decides to implement a machine learning algorithm on its sold products' data. It was observed that the customers who bought cereals more often tend to buy milk or those who buy eggs tend to buy bacon.\n",
        "\n",
        "**3. Reinforcement Learning-** Reinforcement learning is a type of machine learning method where an **intelligent agent (computer program) interacts with the environment** and learns to act within that.\n",
        "\n",
        "The agent continues doing these three things (take action, change state/remain in the same state, and get feedback), and by doing these actions, he learns and explores the environment.\n",
        "\n",
        "**Example:** Suppose there is an AI agent present within a maze environment, and his goal is to find the diamond. The agent interacts with the environment by performing some actions, and based on those actions, the state of the agent gets changed, and it also receives a reward or penalty as feedback."
      ],
      "metadata": {
        "id": "hC0XJGUkhkBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6- What is Linear regression. What are its assumption and what are advantages and disadvantages**\n",
        "\n",
        "**Linear regression** is a statistical method used to model the relationship between a dependent variable and one or more independent variables. It assumes that there is a linear relationship between the variables, meaning that the change in the dependent variable is proportional to the change in the independent variable.\n",
        "\n",
        "**The assumptions of linear regression include:**\n",
        "\n",
        "**1. Linearity:** The relationship between the dependent and independent variables is linear.\n",
        "\n",
        "**2. Independence:** The observations are independent of each other.\n",
        "\n",
        "**3. Homoscedasticity:**The variance of the errors is constant across all levels of the independent variable.\n",
        "\n",
        "**4. Normality:** The errors are normally distributed.\n",
        "\n",
        "In this we mainly try to find best fit line by using gradient decent\n",
        "\n",
        "The **best fit line** is a straight line that represents the relationship between the dependent and independent variables in a linear regression model. It is calculated using a mathematical formula that **minimizes the sum of the squared errors** between the predicted values and the actual values.\n",
        "\n",
        "**Gradient descent** is an optimization algorithm used to find the best fit line in linear regression. It works by iteratively adjusting the parameters of the line to minimize the cost function, which measures the difference between the predicted values and the actual values. The algorithm starts with an initial guess for the parameters and updates them in small steps until it converges to the optimal values."
      ],
      "metadata": {
        "id": "pB2gTZo6YgDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is multicollinearity and how we can remove it?**\n",
        "\n",
        "**Multicollinearity** is a phenomenon that occurs when two or more predictor variables in a regression model are highly correlated with each other. This can cause problems in the model, such as making it difficult to determine the individual effects of each predictor variable on the outcome variable.\n",
        "\n",
        "**There are several ways to measure multicollinearity, including:**\n",
        "\n",
        "**1. Correlation matrix:** A correlation matrix can be used to identify highly correlated predictor variables.\n",
        "\n",
        "**2. Variance Inflation Factor (VIF):** VIF measures the degree to which the variance of the estimated regression coefficient is increased due to multicollinearity. A VIF value greater than 5 or 10 indicates a high degree of multicollinearity.\n",
        "\n",
        "**To remove multicollinearity, we can take the following steps:**\n",
        "\n",
        "1. Remove one of the highly correlated predictor variables from the model.\n",
        "\n",
        "2. Combine the highly correlated predictor variables into a single variable.\n",
        "\n",
        "3. Use dimensionality reduction techniques such as principal component analysis (PCA) to reduce the number of predictor variables in the model.\n",
        "\n",
        "4. Use regularization techniques such as ridge regression or Lasso regression to penalize the coefficients of highly correlated predictor variables."
      ],
      "metadata": {
        "id": "y7JRFbXUbGYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are the evaluation metrics we use and which metrics will best perform and why?**\n",
        "\n",
        "The choice of evaluation metric in regression depends on the specific problem being addressed and the goals of the analysis. Some commonly used evaluation metrics in regression include:\n",
        "\n",
        "**1. Mean Squared Error (MSE):** MSE measures the average squared difference between the predicted and actual values. It is a popular metric because it is easy to interpret and penalizes large errors more heavily.\n",
        "\n",
        "**2. Root Mean Squared Error (RMSE):** RMSE is the square root of the MSE and provides a more interpretable measure of the average error.\n",
        "\n",
        "**3. Mean Absolute Error (MAE):** MAE measures the average absolute difference between the predicted and actual values. It is less sensitive to outliers than MSE and RMSE.\n",
        "\n",
        "**4. R-squared (R2):** R2 measures the proportion of variance in the outcome variable that is explained by the predictor variables. It is a popular metric because it provides a measure of goodness of fit and can be compared across models.\n",
        "\n",
        "The best evaluation metric depends on the specific problem being addressed and the goals of the analysis. For example, if the goal is to minimize the average error between predicted and actual values, then MSE or RMSE may be appropriate. If the goal is to identify the most important predictor variables, then R2 may be more useful. Ultimately, the choice of evaluation metric should be based on a careful consideration of the specific problem being addressed and the goals of the analysis."
      ],
      "metadata": {
        "id": "4nM0KohAdiOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is bias variance tradeoff and how we can remove this**\n",
        "\n",
        "**Bias-variance tradeoff** refers to the tradeoff between the ability of a model to fit the training data well (low bias) and its ability to generalize to new data (low variance). \n",
        "\n",
        "*A model with high bias will underfit the data, meaning it is too simple and does not capture the complexity of the data. A model with high variance will overfit the data, meaning it is too complex and captures noise in the data.*\n",
        "\n",
        "**To remove bias,** we can use a more complex model or increase the number of features. To remove variance, we can use a simpler model or reduce the number of features. Regularization techniques such as L1 and L2 regularization can also help balance bias and variance.\n",
        "\n",
        "**Underfitting**occurs when a model is too simple to capture the underlying patterns in the data. This can happen when the model has too few features or when the regularization parameter is too high. To address underfitting, we can use a more complex model, increase the number of features, or reduce the regularization parameter.\n",
        "\n",
        "**Overfitting** occurs when a model is too complex and captures noise in the data. This can happen when the model has too many features or when the regularization parameter is too low. To address overfitting, we can use a simpler model, reduce the number of features, or increase the regularization parameter. Cross-validation techniques such as k-fold cross-validation can also help identify overfitting.\n",
        "\n",
        "underfitting the training data when the model performs poorly on the training data. \n",
        "\n",
        "Overfitting is an undesirable machine learning behavior that occurs when the machine learning model gives accurate predictions for training data but not for new data. "
      ],
      "metadata": {
        "id": "bGx5nPX4fK3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is regularized linear regression and what is ridge and lassso and how do we choose between two to use?**\n",
        "\n",
        "**Regularized linear regression** is a type of linear regression that includes a regularization term in the loss function to balance bias and variance. The regularization term penalizes large coefficients, which helps to reduce overfitting and improve generalization performance.\n",
        "\n",
        "Ridge regression and Lasso regression are two common types of regularized linear regression. **Ridge regression** adds a **L2 **penalty term to the loss function, while **Lasso** regression adds a **L1** penalty term. The main difference between the two is that Ridge regression shrinks all coefficients towards zero, while Lasso regression can shrink some coefficients to exactly zero, effectively performing feature selection.\n",
        "\n",
        "**To choose between Ridge and Lasso regression,** it depends on the specific problem and the nature of the data. If there are many features with small to medium effect sizes, Ridge regression may be more appropriate. If there are only a few important features with large effect sizes, Lasso regression may be more appropriate for feature selection. In general, it is recommended to try both methods and compare their performance using cross-validation techniques."
      ],
      "metadata": {
        "id": "5dUYV_MYjWTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is logistic regression? and what are its use and why do we need this?**\n",
        "\n",
        "Logistic regression is a statistical technique used to model and analyze binary binary outcome. It is a type of regression analysis that is used to predict the probality of a binary outcome(eg. success or failure) based on one or more predictor variables.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3seNf6iRY5XR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is confusion matrix? what are accuracy, precision, recall and f1 score? How it will help in logistic regression?**"
      ],
      "metadata": {
        "id": "3KUHNfK8dShK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **confusion matrix** is a table that is used to evaluate the performance of a classification model. It compares the actual values of the target variable with the predicted values of the model.\n",
        "\n",
        "**Accuracy** is the proportion of correct predictions made by the model. It is calculated as (true positives + true negatives) / (true positives + true negatives + false positives + false negatives).\n",
        "\n",
        "**Precision** is the proportion of true positives (correctly predicted positive cases) out of all positive predictions made by the model. It is calculated as true positives / (true positives + false positives).\n",
        "\n",
        "**Recall** (also known as sensitivity) is the proportion of true positives out of all actual positive cases. It is calculated as true positives / (true positives + false negatives).\n",
        "\n",
        "**F1 score** is a measure that combines precision and recall into a single metric. It is calculated as 2 * ((precision * recall) / (precision + recall)).\n",
        "\n",
        "These metrics help in evaluating the performance of a logistic regression model. Accuracy gives an overall idea of how well the model is performing, while precision and recall provide information about how well the model is predicting positive cases. The F1 score takes into account both precision and recall, and provides a balanced measure of the model's performance. By analyzing these metrics, we can identify areas where the model needs improvement and make adjustments to improve its performance."
      ],
      "metadata": {
        "id": "9Ike1vFtfjEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mVa6oTUBflsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is decision tree? How do we split explain methods in detail and what are advantage and desadvantages of decision tree? And how do we stop overfitting in decision tree?**"
      ],
      "metadata": {
        "id": "XiVqUsWSeGJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **decision tree** is a machine learning algorithm used for both classification and regression tasks. It is a tree-like model where each internal node represents a test on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label or a numerical value.\n",
        "\n",
        "**Splitting** a decision tree refers to the process of dividing a node into two or more sub-nodes based on the values of an attribute. The goal is to create sub-nodes that are as homogeneous as possible in terms of the target variable. There are several methods for splitting a decision tree, including:\n",
        "\n",
        "**1. Gini Index:** Measures the impurity of a node by calculating the probability of misclassification if a random sample were to be assigned to that node.Calculate Gini for sub nodes, using formula sum of square of probality of success and failure.\n",
        "\n",
        "**2. Entropy:** Measures the impurity of a node by calculating the amount of information needed to classify a new instance in that node.\n",
        "\n",
        "**3. Information Gain:** Measures the reduction in entropy or impurity achieved by splitting a node on an attribute.\n",
        "\n",
        "**4. Chi-Square:** Tests whether the observed frequency distribution of a categorical variable differs significantly from the expected frequency distribution.\n",
        "\n",
        "**The advantages of decision trees include:**\n",
        "\n",
        "**1. Easy to understand and interpret:** Decision trees are easy to visualize and explain, making them useful for both technical and non-technical audiences.\n",
        "\n",
        "**2. Can handle both categorical and numerical data:** Decision trees can handle both categorical and numerical data without requiring any special pre-processing.\n",
        "\n",
        "**3. Can handle missing values:** Decision trees can handle missing values by estimating them based on available data.\n",
        "\n",
        "**4. Can handle non-linear relationships:** Decision trees can capture non-linear relationships between variables without requiring any transformations.\n",
        "\n",
        "**The disadvantages of decision trees include:**\n",
        "\n",
        "**1. Overfitting:** Decision trees can easily overfit the training data, leading to poor generalization performance on new data.\n",
        "\n",
        "**2. Instability:** Small changes in the training data can lead to large changes in the decision tree, making them unstable.\n",
        "\n",
        "**3. Bias:** Decision trees can be biased towards features with many levels or high cardinality.\n",
        "\n",
        "**To prevent overfitting in decision trees, we can use the following methods:**\n",
        "\n",
        "**1. Pruning:** Remove branches that do not improve the overall performance of the tree.\n",
        "\n",
        "**2. Setting a minimum number of samples per leaf:** Stop splitting a node when the number of samples in a leaf node falls below a certain threshold.\n",
        "\n",
        "**3. Setting a maximum depth:** Limit the maximum depth of the decision tree to prevent it from becoming too complex.\n",
        "\n",
        "**4. Ensemble methods:** Combine multiple decision trees to improve their performance and reduce overfitting."
      ],
      "metadata": {
        "id": "1eGMSoWNfuTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is box plot and what are its uses and what its advantages?**"
      ],
      "metadata": {
        "id": "pZwxn-kUmGdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C8hKFvcejVB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CJEoOppal542"
      }
    }
  ]
}